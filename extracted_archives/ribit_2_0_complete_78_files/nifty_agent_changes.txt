Summary of Changes: Original 'nifty' (chatbot) vs. 'nifty_agent' (GUI Automation)

It's important to clarify that the 'nifty_agent' package developed here is not a direct modification or fork of the 'nifty' chatbot repository (https://github.com/cirrus365/nifty) that was initially discussed. Instead, 'nifty_agent' is a completely new, independent project designed for GUI automation, using the 'nifty' naming convention as requested.

Therefore, a direct line-by-line 'diff' between the two projects would not be meaningful. This document outlines the conceptual differences and lists the new components and significant logic implemented in the 'nifty_agent' package.

**1. Original 'nifty' (Chatbot) Project:**
   - **Purpose:** An AI chatbot designed for interaction on platforms like Matrix, Discord, etc.
   - **Core Functionality:** Primarily text-based communication, message processing, and integration with chat protocols.
   - **GUI Interaction:** No inherent capabilities for controlling a graphical user interface (mouse, keyboard, screen vision).

**2. 'nifty_agent' (GUI Automation) Project:**
   - **Purpose:** An AI agent designed to control a computer's graphical user interface (GUI) as if a human user were operating it.
   - **Core Functionality:**
     - **Vision:** Captures screenshots of the screen and converts them into a simplified ASCII text representation for a low-resource LLM.
     - **Decision Making:** Integrates with an external LLM (referred to as 'nifty' LLM) that processes the ASCII vision and a system prompt to output specific action commands.
     - **Action Execution:** Translates LLM commands into physical GUI actions (mouse movements, clicks, keyboard input, running applications).
     - **Loop:** Operates in a continuous See-Think-Act loop, observing the screen, deciding on an action, and executing it.
   - **GUI Interaction:** Full control over mouse, keyboard, and ability to launch applications.

**3. New Files and Core Components in 'nifty_agent' Package:**

   The 'nifty_agent' package was built from scratch with the following structure and key files:

   - **`nifty_agent_package/` (Root directory for the Python package)**
     - **`setup.py`**: Standard Python setup file for package metadata, dependencies, and entry points.
     - **`README.md`**: Documentation for the package.
     - **`nifty_agent/` (Python package directory)**
       - **`__init__.py`**: Initializes the Python package and exposes key modules.
       - **`agent.py`**: Contains the `NiftyAgent` class, which orchestrates the main See-Think-Act loop. This is the core logic that:
         - Takes screenshots and converts them to ASCII (using `image_to_ascii_dithered`).
         - Formulates prompts for the LLM with visual data and the goal.
         - Parses LLM decisions (function calls) and executes them via the `VisionSystemController`.
         - Includes logic for screen change detection and handling LLM uncertainty.
         - Provides a `main_cli` function for command-line execution.
       - **`controller.py`**: Defines the `VisionSystemController` class. This class encapsulates the actual GUI interaction methods:
         - `move_mouse(x, y)`: Moves the mouse cursor.
         - `click()`: Performs a mouse click.
         - `type_text(text)`: Types text using the keyboard.
         - `press_key(key)`: Presses a specific keyboard key.
         - `run_command(command)`: Executes a system command (e.g., launching an application).
         - Includes conditional imports for `pyautogui` and `pynput` for real GUI control, falling back to mock functionality if GUI libraries are unavailable or in a headless environment.
       - **`llm_wrapper.py`**: Defines the `NiftyLLM` class, which is an abstract interface for interacting with an external LLM executable. It handles sending prompts and receiving decisions via standard I/O.
       - **`mock_llm_wrapper.py`**: Implements `MockNiftyLLM`, a concrete mock version of `NiftyLLM` for simulation and testing. It provides predefined responses to simulate LLM behavior without needing a real executable.
       - **`mock_controller.py`**: Implements `MockVisionSystemController`, a concrete mock version of `VisionSystemController` for simulation and testing in headless environments. It logs simulated actions instead of performing real GUI interactions.

**4. Key Architectural Differences & Enhancements:**
   - **Vision System:** The `image_to_ascii_dithered` function (with Numba JIT compilation and Floyd-Steinberg dithering) is a critical component for providing efficient visual input to a low-resource LLM.
   - **Robust Action Parsing:** Uses `ast.literal_eval` for safe parsing of LLM-generated function calls, preventing arbitrary code execution.
   - **Safety Features:** Includes `pyautogui.FAILSAFE` and mouse clamping to prevent erratic behavior.
   - **Performance Optimizations:** Screen change detection and caching (`diff < 0.05`) to reduce redundant LLM queries.
   - **Modularity:** Designed with clear separation of concerns (LLM interaction, GUI control, agent logic) to allow for easy swapping of components (e.g., real LLM vs. mock LLM, real controller vs. mock controller).

In essence, the 'nifty_agent' is a framework for creating autonomous GUI agents, leveraging a low-resource LLM for decision-making based on visual (ASCII) input. It's a specialized tool for a very different purpose than the original 'nifty' chatbot.

